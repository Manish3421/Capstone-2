{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "678e4113-240d-4fc0-84fb-44261b9597fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerKey  Gender               Name            City State Code  \\\n",
      "0          301  Female      Lilly Harding  WANDEARAH EAST         SA   \n",
      "1          325  Female       Madison Hull      MOUNT BUDD         WA   \n",
      "2          554  Female      Claire Ferres       WINJALLOK        VIC   \n",
      "3          786    Male  Jai Poltpalingada    MIDDLE RIVER         SA   \n",
      "4         1042    Male    Aidan Pankhurst   TAWONGA SOUTH        VIC   \n",
      "\n",
      "               State Zip Code    Country  Continent    Birthday  \n",
      "0    South Australia     5523  Australia  Australia    7/3/1939  \n",
      "1  Western Australia     6522  Australia  Australia   9/27/1979  \n",
      "2           Victoria     3380  Australia  Australia   5/26/1947  \n",
      "3    South Australia     5223  Australia  Australia   9/17/1957  \n",
      "4           Victoria     3698  Australia  Australia  11/19/1965  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   CustomerKey  15266 non-null  int64 \n",
      " 1   Gender       15266 non-null  object\n",
      " 2   Name         15266 non-null  object\n",
      " 3   City         15266 non-null  object\n",
      " 4   State Code   15256 non-null  object\n",
      " 5   State        15266 non-null  object\n",
      " 6   Zip Code     15266 non-null  object\n",
      " 7   Country      15266 non-null  object\n",
      " 8   Continent    15266 non-null  object\n",
      " 9   Birthday     15266 non-null  object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Customers dataset\n",
    "customers = pd.read_csv(r'C:\\Users\\manis\\Downloads\\Customers.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "# Display the first few rows and general information about the dataset\n",
    "print(customers.head())\n",
    "print(customers.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c865437-5a51-46cc-939b-0284e111b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15266 entries, 0 to 15265\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   CustomerKey  15266 non-null  int64         \n",
      " 1   Gender       15266 non-null  object        \n",
      " 2   Name         15266 non-null  object        \n",
      " 3   City         15266 non-null  object        \n",
      " 4   State Code   15266 non-null  object        \n",
      " 5   State        15266 non-null  object        \n",
      " 6   Zip Code     15266 non-null  object        \n",
      " 7   Country      15266 non-null  object        \n",
      " 8   Continent    15266 non-null  object        \n",
      " 9   Birthday     15266 non-null  datetime64[ns]\n",
      " 10  Age          15266 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(8)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "   CustomerKey  Gender               Name            City State Code  \\\n",
      "0          301  Female      Lilly Harding  WANDEARAH EAST         SA   \n",
      "1          325  Female       Madison Hull      MOUNT BUDD         WA   \n",
      "2          554  Female      Claire Ferres       WINJALLOK        VIC   \n",
      "3          786    Male  Jai Poltpalingada    MIDDLE RIVER         SA   \n",
      "4         1042    Male    Aidan Pankhurst   TAWONGA SOUTH        VIC   \n",
      "\n",
      "               State Zip Code    Country  Continent   Birthday  Age  \n",
      "0    South Australia     5523  Australia  Australia 1939-07-03   85  \n",
      "1  Western Australia     6522  Australia  Australia 1979-09-27   45  \n",
      "2           Victoria     3380  Australia  Australia 1947-05-26   77  \n",
      "3    South Australia     5223  Australia  Australia 1957-09-17   67  \n",
      "4           Victoria     3698  Australia  Australia 1965-11-19   58  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Handle Missing Values for State Code\n",
    "customers['State Code'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Step 2: Convert 'Birthday' to datetime\n",
    "customers['Birthday'] = pd.to_datetime(customers['Birthday'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Step 3: Calculate Age\n",
    "customers['Age'] = (pd.to_datetime('today') - customers['Birthday']).dt.days // 365\n",
    "\n",
    "# Check the updated dataframe info\n",
    "print(customers.info())\n",
    "\n",
    "# Optionally, check the first few rows again\n",
    "print(customers.head())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "customers.to_csv('C:/Users/manis/Downloads/Cleaned_Customers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a50089-b2b0-4d99-9eff-4fb32c26a189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date Currency  Exchange\n",
      "0  1/1/2015      USD    1.0000\n",
      "1  1/1/2015      CAD    1.1583\n",
      "2  1/1/2015      AUD    1.2214\n",
      "3  1/1/2015      EUR    0.8237\n",
      "4  1/1/2015      GBP    0.6415\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11215 entries, 0 to 11214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      11215 non-null  object \n",
      " 1   Currency  11215 non-null  object \n",
      " 2   Exchange  11215 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 263.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Exchange Rates dataset\n",
    "exchange_rates = pd.read_csv(r'C:\\Users\\manis\\Downloads\\Exchange_rates.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows and general information about the dataset\n",
    "print(exchange_rates.head())\n",
    "print(exchange_rates.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f734deb6-b35f-476c-8a64-451e15df39dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11215 entries, 0 to 11214\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      11215 non-null  datetime64[ns]\n",
      " 1   Currency  11215 non-null  object        \n",
      " 2   Exchange  11215 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 263.0+ KB\n",
      "None\n",
      "        Date Currency  Exchange\n",
      "0 2015-01-01      USD    1.0000\n",
      "1 2015-01-01      CAD    1.1583\n",
      "2 2015-01-01      AUD    1.2214\n",
      "3 2015-01-01      EUR    0.8237\n",
      "4 2015-01-01      GBP    0.6415\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert 'Date' to datetime\n",
    "exchange_rates['Date'] = pd.to_datetime(exchange_rates['Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Step 2: Check for duplicates\n",
    "duplicates = exchange_rates.duplicated(subset=['Date', 'Currency']).sum()\n",
    "print(f\"Number of duplicate entries: {duplicates}\")\n",
    "\n",
    "# Step 3: Strip any whitespace in the 'Currency' column\n",
    "exchange_rates['Currency'] = exchange_rates['Currency'].str.strip()\n",
    "\n",
    "# Check the updated dataframe info\n",
    "print(exchange_rates.info())\n",
    "\n",
    "# Optionally, check the first few rows again\n",
    "print(exchange_rates.head())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "exchange_rates.to_csv('C:/Users/manis/Downloads/Cleaned_Exchange_Rates.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f22a72-c83f-40a2-a4ad-a65b2927be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order Number  Line Item Order Date Delivery Date  CustomerKey  StoreKey  \\\n",
      "0        366000          1   1/1/2016           NaN       265598        10   \n",
      "1        366001          1   1/1/2016     1/13/2016      1269051         0   \n",
      "2        366001          2   1/1/2016     1/13/2016      1269051         0   \n",
      "3        366002          1   1/1/2016     1/12/2016       266019         0   \n",
      "4        366002          2   1/1/2016     1/12/2016       266019         0   \n",
      "\n",
      "   ProductKey  Quantity Currency Code  \n",
      "0        1304         1           CAD  \n",
      "1        1048         2           USD  \n",
      "2        2007         1           USD  \n",
      "3        1106         7           CAD  \n",
      "4         373         1           CAD  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62884 entries, 0 to 62883\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Order Number   62884 non-null  int64 \n",
      " 1   Line Item      62884 non-null  int64 \n",
      " 2   Order Date     62884 non-null  object\n",
      " 3   Delivery Date  13165 non-null  object\n",
      " 4   CustomerKey    62884 non-null  int64 \n",
      " 5   StoreKey       62884 non-null  int64 \n",
      " 6   ProductKey     62884 non-null  int64 \n",
      " 7   Quantity       62884 non-null  int64 \n",
      " 8   Currency Code  62884 non-null  object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 4.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Sales dataset\n",
    "sales = pd.read_csv(r'C:\\Users\\manis\\Downloads\\Sales.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows and general information about the dataset\n",
    "print(sales.head())\n",
    "print(sales.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658e14c3-5444-40d0-bb30-835ba6d83a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62884 entries, 0 to 62883\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   Order Number   62884 non-null  int64         \n",
      " 1   Line Item      62884 non-null  int64         \n",
      " 2   Order Date     62884 non-null  datetime64[ns]\n",
      " 3   Delivery Date  13165 non-null  datetime64[ns]\n",
      " 4   CustomerKey    62884 non-null  int64         \n",
      " 5   StoreKey       62884 non-null  int64         \n",
      " 6   ProductKey     62884 non-null  int64         \n",
      " 7   Quantity       62884 non-null  int64         \n",
      " 8   Currency Code  62884 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(6), object(1)\n",
      "memory usage: 4.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert date columns to datetime\n",
    "sales['Order Date'] = pd.to_datetime(sales['Order Date'], format='%m/%d/%Y', errors='coerce')\n",
    "sales['Delivery Date'] = pd.to_datetime(sales['Delivery Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Step 2: Handle missing values in Delivery Date\n",
    "# Option 1: Fill with a specific date or keep as NaT\n",
    "# sales['Delivery Date'].fillna(pd.Timestamp('today'), inplace=True)  # Uncomment if you want to fill\n",
    "# Option 2: Drop rows with missing Delivery Date\n",
    "# sales.dropna(subset=['Delivery Date'], inplace=True)  # Uncomment to drop rows\n",
    "\n",
    "# Step 3: Check for duplicates\n",
    "duplicates = sales.duplicated().sum()\n",
    "print(f\"Number of duplicate entries: {duplicates}\")\n",
    "\n",
    "# Display updated info\n",
    "print(sales.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42cf31cc-0cba-4506-bc8b-ece24590d41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreKey    Country                         State  Square Meters  Open Date\n",
      "0         1  Australia  Australian Capital Territory          595.0   1/1/2008\n",
      "1         2  Australia            Northern Territory          665.0  1/12/2008\n",
      "2         3  Australia               South Australia         2000.0   1/7/2012\n",
      "3         4  Australia                      Tasmania         2000.0   1/1/2010\n",
      "4         5  Australia                      Victoria         2000.0  12/9/2015\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   StoreKey       67 non-null     int64  \n",
      " 1   Country        67 non-null     object \n",
      " 2   State          67 non-null     object \n",
      " 3   Square Meters  66 non-null     float64\n",
      " 4   Open Date      67 non-null     object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 2.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Stores.csv data\n",
    "stores = pd.read_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Stores.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows and data information\n",
    "print(stores.head())\n",
    "print(stores.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cb9375-9f0b-4da0-baef-2e9eea973c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " StoreKey         0\n",
      "Country          0\n",
      "State            0\n",
      "Square Meters    1\n",
      "Open Date        0\n",
      "dtype: int64\n",
      "Number of duplicate entries: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   StoreKey       67 non-null     int64         \n",
      " 1   Country        67 non-null     object        \n",
      " 2   State          67 non-null     object        \n",
      " 3   Square Meters  67 non-null     float64       \n",
      " 4   Open Date      67 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(2)\n",
      "memory usage: 2.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = stores.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = stores.duplicated().sum()\n",
    "print(\"Number of duplicate entries:\", duplicates)\n",
    "\n",
    "# Convert 'Open Date' to datetime format\n",
    "stores['Open Date'] = pd.to_datetime(stores['Open Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Handle missing values in 'Square Meters' (let's fill it with the mean as an example)\n",
    "mean_square_meters = stores['Square Meters'].mean()\n",
    "stores['Square Meters'].fillna(mean_square_meters, inplace=True)\n",
    "\n",
    "# Final data information after cleaning\n",
    "print(stores.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2540c3-363b-45c6-94d2-cbc2d91a19fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductKey                         Product Name    Brand   Color  \\\n",
      "0           1  Contoso 512MB MP3 Player E51 Silver  Contoso  Silver   \n",
      "1           2    Contoso 512MB MP3 Player E51 Blue  Contoso    Blue   \n",
      "2           3     Contoso 1G MP3 Player E100 White  Contoso   White   \n",
      "3           4    Contoso 2G MP3 Player E200 Silver  Contoso  Silver   \n",
      "4           5       Contoso 2G MP3 Player E200 Red  Contoso     Red   \n",
      "\n",
      "  Unit Cost USD Unit Price USD  SubcategoryKey Subcategory  CategoryKey  \\\n",
      "0        $6.62         $12.99              101     MP4&MP3            1   \n",
      "1        $6.62         $12.99              101     MP4&MP3            1   \n",
      "2        $7.40         $14.52              101     MP4&MP3            1   \n",
      "3       $11.00         $21.57              101     MP4&MP3            1   \n",
      "4       $11.00         $21.57              101     MP4&MP3            1   \n",
      "\n",
      "  Category  \n",
      "0    Audio  \n",
      "1    Audio  \n",
      "2    Audio  \n",
      "3    Audio  \n",
      "4    Audio  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ProductKey      2517 non-null   int64 \n",
      " 1   Product Name    2517 non-null   object\n",
      " 2   Brand           2517 non-null   object\n",
      " 3   Color           2517 non-null   object\n",
      " 4   Unit Cost USD   2517 non-null   object\n",
      " 5   Unit Price USD  2517 non-null   object\n",
      " 6   SubcategoryKey  2517 non-null   int64 \n",
      " 7   Subcategory     2517 non-null   object\n",
      " 8   CategoryKey     2517 non-null   int64 \n",
      " 9   Category        2517 non-null   object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 196.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Stores.csv data\n",
    "Products = pd.read_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Products.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows and data information\n",
    "print(Products.head())\n",
    "print(Products.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21791d19-0b2f-479b-9eed-44bd6d9860b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " ProductKey        0\n",
      "Product Name      0\n",
      "Brand             0\n",
      "Color             0\n",
      "Unit Cost USD     0\n",
      "Unit Price USD    0\n",
      "SubcategoryKey    0\n",
      "Subcategory       0\n",
      "CategoryKey       0\n",
      "Category          0\n",
      "dtype: int64\n",
      "Number of duplicate entries: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2517 entries, 0 to 2516\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   ProductKey      2517 non-null   int64  \n",
      " 1   Product Name    2517 non-null   object \n",
      " 2   Brand           2517 non-null   object \n",
      " 3   Color           2517 non-null   object \n",
      " 4   Unit Cost USD   2517 non-null   float64\n",
      " 5   Unit Price USD  2517 non-null   float64\n",
      " 6   SubcategoryKey  2517 non-null   int64  \n",
      " 7   Subcategory     2517 non-null   object \n",
      " 8   CategoryKey     2517 non-null   int64  \n",
      " 9   Category        2517 non-null   object \n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 196.8+ KB\n",
      "None\n",
      "   ProductKey                         Product Name    Brand   Color  \\\n",
      "0           1  Contoso 512MB MP3 Player E51 Silver  Contoso  Silver   \n",
      "1           2    Contoso 512MB MP3 Player E51 Blue  Contoso    Blue   \n",
      "2           3     Contoso 1G MP3 Player E100 White  Contoso   White   \n",
      "3           4    Contoso 2G MP3 Player E200 Silver  Contoso  Silver   \n",
      "4           5       Contoso 2G MP3 Player E200 Red  Contoso     Red   \n",
      "\n",
      "   Unit Cost USD  Unit Price USD  SubcategoryKey Subcategory  CategoryKey  \\\n",
      "0           6.62           12.99             101     MP4&MP3            1   \n",
      "1           6.62           12.99             101     MP4&MP3            1   \n",
      "2           7.40           14.52             101     MP4&MP3            1   \n",
      "3          11.00           21.57             101     MP4&MP3            1   \n",
      "4          11.00           21.57             101     MP4&MP3            1   \n",
      "\n",
      "  Category  \n",
      "0    Audio  \n",
      "1    Audio  \n",
      "2    Audio  \n",
      "3    Audio  \n",
      "4    Audio  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Products data\n",
    "products = pd.read_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Products.csv', encoding='latin1')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = products.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicate_count = products.duplicated().sum()\n",
    "print(\"Number of duplicate entries:\", duplicate_count)\n",
    "\n",
    "# Convert 'Unit Cost USD' and 'Unit Price USD' to numeric\n",
    "products['Unit Cost USD'] = products['Unit Cost USD'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "products['Unit Price USD'] = products['Unit Price USD'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# Convert other columns to string type if necessary\n",
    "products['Product Name'] = products['Product Name'].astype(str)\n",
    "products['Brand'] = products['Brand'].astype(str)\n",
    "products['Color'] = products['Color'].astype(str)\n",
    "products['Subcategory'] = products['Subcategory'].astype(str)\n",
    "products['Category'] = products['Category'].astype(str)\n",
    "\n",
    "# Standardize column names (optional)\n",
    "products.columns = products.columns.str.strip()\n",
    "\n",
    "# Display cleaned data information\n",
    "print(products.info())\n",
    "print(products.head())\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "products.to_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Cleaned_Products.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00aea285-2768-462b-a505-69b60c2f2c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order Number  Line Item Order Date Delivery Date  CustomerKey  StoreKey  \\\n",
      "0        366000          1   1/1/2016           NaN       265598        10   \n",
      "1        366001          1   1/1/2016     1/13/2016      1269051         0   \n",
      "2        366001          2   1/1/2016     1/13/2016      1269051         0   \n",
      "3        366002          1   1/1/2016     1/12/2016       266019         0   \n",
      "4        366002          2   1/1/2016     1/12/2016       266019         0   \n",
      "\n",
      "   ProductKey  Quantity Currency Code  \n",
      "0        1304         1           CAD  \n",
      "1        1048         2           USD  \n",
      "2        2007         1           USD  \n",
      "3        1106         7           CAD  \n",
      "4         373         1           CAD  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62884 entries, 0 to 62883\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Order Number   62884 non-null  int64 \n",
      " 1   Line Item      62884 non-null  int64 \n",
      " 2   Order Date     62884 non-null  object\n",
      " 3   Delivery Date  13165 non-null  object\n",
      " 4   CustomerKey    62884 non-null  int64 \n",
      " 5   StoreKey       62884 non-null  int64 \n",
      " 6   ProductKey     62884 non-null  int64 \n",
      " 7   Quantity       62884 non-null  int64 \n",
      " 8   Currency Code  62884 non-null  object\n",
      "dtypes: int64(6), object(3)\n",
      "memory usage: 4.3+ MB\n",
      "None\n",
      "Order Number         0\n",
      "Line Item            0\n",
      "Order Date           0\n",
      "Delivery Date    49719\n",
      "CustomerKey          0\n",
      "StoreKey             0\n",
      "ProductKey           0\n",
      "Quantity             0\n",
      "Currency Code        0\n",
      "dtype: int64\n",
      "Number of duplicate entries: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manis\\AppData\\Local\\Temp\\ipykernel_264\\3425328389.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'No Delivery Date' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  sales['Delivery Date'].fillna('No Delivery Date', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Sales data\n",
    "sales = pd.read_csv(r'C:\\Users\\manis\\Downloads\\Sales.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows and info\n",
    "print(sales.head())\n",
    "print(sales.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(sales.isnull().sum())\n",
    "\n",
    "# Clean the data\n",
    "# Example: Convert 'Order Date' and 'Delivery Date' to datetime\n",
    "sales['Order Date'] = pd.to_datetime(sales['Order Date'])\n",
    "sales['Delivery Date'] = pd.to_datetime(sales['Delivery Date'])\n",
    "\n",
    "# Fill or drop missing values if necessary\n",
    "sales['Delivery Date'].fillna('No Delivery Date', inplace=True)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = sales.duplicated().sum()\n",
    "print(f'Number of duplicate entries: {duplicates}')\n",
    "\n",
    "# Save the cleaned sales data\n",
    "sales.to_csv('cleaned_sales.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7bb9d3-75a8-4385-99aa-b0117cdf9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StoreKey    Country                         State  Square Meters  Open Date\n",
      "0         1  Australia  Australian Capital Territory          595.0   1/1/2008\n",
      "1         2  Australia            Northern Territory          665.0  1/12/2008\n",
      "2         3  Australia               South Australia         2000.0   1/7/2012\n",
      "3         4  Australia                      Tasmania         2000.0   1/1/2010\n",
      "4         5  Australia                      Victoria         2000.0  12/9/2015\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67 entries, 0 to 66\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   StoreKey       67 non-null     int64  \n",
      " 1   Country        67 non-null     object \n",
      " 2   State          67 non-null     object \n",
      " 3   Square Meters  66 non-null     float64\n",
      " 4   Open Date      67 non-null     object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 2.7+ KB\n",
      "None\n",
      "StoreKey         0\n",
      "Country          0\n",
      "State            0\n",
      "Square Meters    1\n",
      "Open Date        0\n",
      "dtype: int64\n",
      "Number of duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the Stores data\n",
    "stores = pd.read_csv(r'C:\\Users\\manis\\Downloads\\Stores.csv', encoding='latin1')\n",
    "\n",
    "# Display the first few rows and info\n",
    "print(stores.head())\n",
    "print(stores.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(stores.isnull().sum())\n",
    "\n",
    "# Clean the data\n",
    "# Example: Convert 'Open Date' to datetime\n",
    "stores['Open Date'] = pd.to_datetime(stores['Open Date'])\n",
    "\n",
    "# Fill or drop missing values if necessary\n",
    "stores['Square Meters'].fillna(stores['Square Meters'].mean(), inplace=True)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = stores.duplicated().sum()\n",
    "print(f'Number of duplicate entries: {duplicates}')\n",
    "\n",
    "# Save the cleaned stores data\n",
    "stores.to_csv('cleaned_stores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53bb2af4-3d4f-4d85-b0d6-436d4ecdeef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in sales_products_customers_stores:\n",
      "Index(['Order Number', 'Line Item', 'Order Date', 'Delivery Date',\n",
      "       'CustomerKey', 'StoreKey', 'ProductKey', 'Quantity', 'Currency Code',\n",
      "       'Product Name', 'Brand', 'Color', 'Unit Cost USD', 'Unit Price USD',\n",
      "       'SubcategoryKey', 'Subcategory', 'CategoryKey', 'Category', 'Gender',\n",
      "       'Name', 'City', 'State Code', 'State_x', 'Zip Code', 'Country_x',\n",
      "       'Continent', 'Birthday', 'Age', 'Country_y', 'State_y', 'Square Meters',\n",
      "       'Open Date'],\n",
      "      dtype='object')\n",
      "Columns in exchange_rates:\n",
      "Index(['Date', 'Currency', 'Exchange'], dtype='object')\n",
      "   Order Number  Line Item  Order Date        Delivery Date  CustomerKey  \\\n",
      "0        366000          1  2016-01-01     No Delivery Date       265598   \n",
      "1        366001          1  2016-01-01  2016-01-13 00:00:00      1269051   \n",
      "2        366001          2  2016-01-01  2016-01-13 00:00:00      1269051   \n",
      "3        366002          1  2016-01-01  2016-01-12 00:00:00       266019   \n",
      "4        366002          2  2016-01-01  2016-01-12 00:00:00       266019   \n",
      "\n",
      "   StoreKey  ProductKey  Quantity Currency Code  \\\n",
      "0        10        1304         1           CAD   \n",
      "1         0        1048         2           USD   \n",
      "2         0        2007         1           USD   \n",
      "3         0        1106         7           CAD   \n",
      "4         0         373         1           CAD   \n",
      "\n",
      "                             Product Name  ...      Country_x      Continent  \\\n",
      "0         Contoso Lens Adapter M450 White  ...         Canada  North America   \n",
      "1         A. Datum SLR Camera X136 Silver  ...  United States  North America   \n",
      "2  Fabrikam Microwave 1.5CuFt X1100 Black  ...  United States  North America   \n",
      "3          Contoso SLR Camera M146 Orange  ...         Canada  North America   \n",
      "4   Adventure Works Laptop8.9 E0890 White  ...         Canada  North America   \n",
      "\n",
      "     Birthday  Age  Country_y  State_y  Square Meters   Open Date        Date  \\\n",
      "0  1971-03-23   53     Canada  Nunavut     1210.00000  2015-04-04  2016-01-01   \n",
      "1  1995-11-20   28     Online   Online     1402.19697  2010-01-01  2016-01-01   \n",
      "2  1995-11-20   28     Online   Online     1402.19697  2010-01-01  2016-01-01   \n",
      "3  1962-08-24   62     Online   Online     1402.19697  2010-01-01  2016-01-01   \n",
      "4  1962-08-24   62     Online   Online     1402.19697  2010-01-01  2016-01-01   \n",
      "\n",
      "  Exchange  \n",
      "0   1.3884  \n",
      "1   1.0000  \n",
      "2   1.0000  \n",
      "3   1.3884  \n",
      "4   1.3884  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned datasets\n",
    "sales = pd.read_csv('cleaned_sales.csv', encoding='latin1')\n",
    "products = pd.read_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Cleaned_Products.csv', encoding='latin1')\n",
    "stores = pd.read_csv('cleaned_stores.csv', encoding='latin1')\n",
    "customers = pd.read_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Cleaned_Customers.csv', encoding='latin1')\n",
    "exchange_rates = pd.read_csv('C:\\\\Users\\\\manis\\\\Downloads\\\\Cleaned_Exchange_Rates.csv', encoding='latin1')\n",
    "\n",
    "# Merging Sales with Products\n",
    "sales_products = pd.merge(sales, products, on='ProductKey', how='left')\n",
    "\n",
    "# Merging the result with Customers\n",
    "sales_products_customers = pd.merge(sales_products, customers, on='CustomerKey', how='left')\n",
    "\n",
    "# Merging the result with Stores\n",
    "sales_products_customers_stores = pd.merge(sales_products_customers, stores, on='StoreKey', how='left')\n",
    "\n",
    "# Check the columns before merging with Exchange Rates\n",
    "print(\"Columns in sales_products_customers_stores:\")\n",
    "print(sales_products_customers_stores.columns)\n",
    "print(\"Columns in exchange_rates:\")\n",
    "print(exchange_rates.columns)\n",
    "\n",
    "# Rename Currency in exchange_rates to match Currency Code\n",
    "exchange_rates.rename(columns={'Currency': 'Currency Code'}, inplace=True)\n",
    "\n",
    "# Now, ensure both DataFrames have the Currency Code column\n",
    "if 'Currency Code' in sales_products_customers_stores.columns and 'Currency Code' in exchange_rates.columns:\n",
    "    # Merging with Exchange Rates\n",
    "    full_data = pd.merge(\n",
    "        sales_products_customers_stores,\n",
    "        exchange_rates,\n",
    "        left_on=['Order Date', 'Currency Code'],\n",
    "        right_on=['Date', 'Currency Code'],\n",
    "        how='left'\n",
    "    )\n",
    "    print(full_data.head())\n",
    "else:\n",
    "    print(\"Currency Code not found in one or both DataFrames.\")\n",
    "\n",
    "# Save the merged dataset if the merge is successful\n",
    "# full_data.to_csv('merged_data_with_exchange_rates.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051b7eb7-bb2b-4528-bd80-9f3bcf693994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order Number  Line Item Order Date        Delivery Date  CustomerKey  \\\n",
      "0        366000          1 2016-01-01     No Delivery Date       265598   \n",
      "1        366001          1 2016-01-01  2016-01-13 00:00:00      1269051   \n",
      "2        366001          2 2016-01-01  2016-01-13 00:00:00      1269051   \n",
      "3        366002          1 2016-01-01  2016-01-12 00:00:00       266019   \n",
      "4        366002          2 2016-01-01  2016-01-12 00:00:00       266019   \n",
      "\n",
      "   StoreKey  ProductKey  Quantity Currency Code  \\\n",
      "0        10        1304         1           CAD   \n",
      "1         0        1048         2           USD   \n",
      "2         0        2007         1           USD   \n",
      "3         0        1106         7           CAD   \n",
      "4         0         373         1           CAD   \n",
      "\n",
      "                             Product Name  ...      Country_x      Continent  \\\n",
      "0         Contoso Lens Adapter M450 White  ...         Canada  North America   \n",
      "1         A. Datum SLR Camera X136 Silver  ...  United States  North America   \n",
      "2  Fabrikam Microwave 1.5CuFt X1100 Black  ...  United States  North America   \n",
      "3          Contoso SLR Camera M146 Orange  ...         Canada  North America   \n",
      "4   Adventure Works Laptop8.9 E0890 White  ...         Canada  North America   \n",
      "\n",
      "     Birthday  Age  Country_y  State_y  Square Meters   Open Date       Date  \\\n",
      "0  1971-03-23   53     Canada  Nunavut     1210.00000  2015-04-04 2016-01-01   \n",
      "1  1995-11-20   28     Online   Online     1402.19697  2010-01-01 2016-01-01   \n",
      "2  1995-11-20   28     Online   Online     1402.19697  2010-01-01 2016-01-01   \n",
      "3  1962-08-24   62     Online   Online     1402.19697  2010-01-01 2016-01-01   \n",
      "4  1962-08-24   62     Online   Online     1402.19697  2010-01-01 2016-01-01   \n",
      "\n",
      "  Exchange  \n",
      "0   1.3884  \n",
      "1   1.0000  \n",
      "2   1.0000  \n",
      "3   1.3884  \n",
      "4   1.3884  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming previous merges have been performed\n",
    "# Rename Currency in exchange_rates to match Currency Code\n",
    "exchange_rates.rename(columns={'Currency': 'Currency Code'}, inplace=True)\n",
    "\n",
    "# Convert 'Order Date' and 'Date' to datetime format if not already done\n",
    "sales_products_customers_stores['Order Date'] = pd.to_datetime(sales_products_customers_stores['Order Date'])\n",
    "exchange_rates['Date'] = pd.to_datetime(exchange_rates['Date'])\n",
    "\n",
    "# Perform the merge with Exchange Rates\n",
    "full_data = pd.merge(\n",
    "    sales_products_customers_stores,\n",
    "    exchange_rates,\n",
    "    left_on=['Order Date', 'Currency Code'],\n",
    "    right_on=['Date', 'Currency Code'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check the result of the merged DataFrame\n",
    "print(full_data.head())\n",
    "\n",
    "# Save the merged dataset if the merge is successful\n",
    "full_data.to_csv('merged_data_with_exchange_rates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6fae08b-a93d-4688-b94f-213a31a5955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Number      0\n",
      "Line Item         0\n",
      "Order Date        0\n",
      "Delivery Date     0\n",
      "CustomerKey       0\n",
      "StoreKey          0\n",
      "ProductKey        0\n",
      "Quantity          0\n",
      "Currency Code     0\n",
      "Product Name      0\n",
      "Brand             0\n",
      "Color             0\n",
      "Unit Cost USD     0\n",
      "Unit Price USD    0\n",
      "SubcategoryKey    0\n",
      "Subcategory       0\n",
      "CategoryKey       0\n",
      "Category          0\n",
      "Gender            0\n",
      "Name              0\n",
      "City              0\n",
      "State Code        0\n",
      "State_x           0\n",
      "Zip Code          0\n",
      "Country_x         0\n",
      "Continent         0\n",
      "Birthday          0\n",
      "Age               0\n",
      "Country_y         0\n",
      "State_y           0\n",
      "Square Meters     0\n",
      "Open Date         0\n",
      "Date              0\n",
      "Exchange          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(full_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a46d889-8177-4eb1-8821-939ef1396c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_csv('merged_full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67ddc3c-4a27-4981-88c9-88800370f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Number               int64\n",
      "Line Item                  int64\n",
      "Order Date        datetime64[ns]\n",
      "Delivery Date             object\n",
      "CustomerKey                int64\n",
      "StoreKey                   int64\n",
      "ProductKey                 int64\n",
      "Quantity                   int64\n",
      "Currency Code             object\n",
      "Product Name              object\n",
      "Brand                     object\n",
      "Color                     object\n",
      "Unit Cost USD            float64\n",
      "Unit Price USD           float64\n",
      "SubcategoryKey             int64\n",
      "Subcategory               object\n",
      "CategoryKey                int64\n",
      "Category                  object\n",
      "Gender                    object\n",
      "Name                      object\n",
      "City                      object\n",
      "State Code                object\n",
      "State_x                   object\n",
      "Zip Code                  object\n",
      "Country_x                 object\n",
      "Continent                 object\n",
      "Birthday                  object\n",
      "Age                        int64\n",
      "Country_y                 object\n",
      "State_y                   object\n",
      "Square Meters            float64\n",
      "Open Date                 object\n",
      "Date              datetime64[ns]\n",
      "Exchange                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(full_data.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed8d9392-c054-49d6-80f0-ca7f5c9c908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = full_data.dropna(subset=['Delivery Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "093866a3-11fe-47dc-b7ab-17f2dfa18112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming full_data is your DataFrame\n",
    "full_data['Delivery Date'].fillna(pd.Timestamp('2023-01-01'), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58e8fed0-dcc3-4c5c-8747-eeca2d321bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\manis\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\manis\\anaconda3\\lib\\site-packages (2.0.25)\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\manis\\anaconda3\\lib\\site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sqlalchemy mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e9a56bf-3e49-4ebd-8f9e-e31af45c6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "full_data = pd.read_csv('C:\\\\Users\\\\manis\\\\merged_full_data.csv')\n",
    "\n",
    "# Replace 'No Delivery Date' with NaT (or any placeholder like '1900-01-01')\n",
    "full_data['Delivery Date'] = full_data['Delivery Date'].replace('No Delivery Date', pd.NaT)\n",
    "\n",
    "# Optionally, you can fill NaT with NULL or a placeholder date\n",
    "full_data['Delivery Date'].fillna('NULL', inplace=True)  # or you could use '1900-01-01'\n",
    "\n",
    "# Save the modified DataFrame back to CSV\n",
    "full_data.to_csv('C:\\\\Users\\\\manis\\\\modified_merged_full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "475af610-2095-492f-9bc5-c37e7d132a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV\n",
    "data = pd.read_csv(r'C:\\Users\\manis\\OneDrive\\Desktop\\merged_full_data - Copy.csv', encoding='latin1')\n",
    "\n",
    "# Rename columns by replacing spaces with underscores\n",
    "data.columns = [col.strip().replace(\" \", \"_\").lower() for col in data.columns]\n",
    "\n",
    "# Save the modified CSV back (optional, if you want to use this in MySQL directly)\n",
    "data.to_csv(r'C:\\Users\\manis\\OneDrive\\Desktop\\modified_merged_full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a46582e5-cd6c-4925-9465-61f816f49f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns in DataFrame: ['Order Number', 'Line Item', 'Order Date', 'Delivery Date', 'CustomerKey', 'StoreKey', 'ProductKey', 'Quantity', 'Currency Code', 'Product Name', 'Brand', 'Color', 'Unit Cost USD', 'Unit Price USD', 'SubcategoryKey', 'Subcategory', 'CategoryKey', 'Category', 'Gender', 'Name', 'City', 'State Code', 'State_x', 'Zip Code', 'Country_x', 'Continent', 'Birthday', 'Age', 'Country_y', 'State_y', 'Square Meters', 'Open Date', 'Date', 'Exchange']\n",
      "Columns after modification: ['order_number', 'line_item', 'order_date', 'delivery_date', 'customer_key', 'store_key', 'product_key', 'quantity', 'currency_code', 'product_name', 'brand', 'color', 'unit_cost_usd', 'unit_price_usd', 'subcategory_key', 'subcategory', 'category_key', 'category', 'gender', 'name', 'city', 'state_code', 'state_x', 'zip_code', 'country_x', 'continent', 'birthday', 'age', 'country_y', 'state_y', 'square_meters', 'open_date', 'Exchanges']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Load the CSV data\n",
    "data = pd.read_csv(r'C:\\Users\\manis\\OneDrive\\Desktop\\merged_full_data - Copy.csv', encoding='latin1')\n",
    "\n",
    "# Print original columns to verify them\n",
    "print(\"Original columns in DataFrame:\", data.columns.tolist())\n",
    "\n",
    "# Rename columns to match MySQL table schema\n",
    "data.rename(columns={\n",
    "    'Order Number': 'order_number',\n",
    "    'Line Item': 'line_item',\n",
    "    'Order Date': 'order_date',\n",
    "    'Delivery Date': 'delivery_date',\n",
    "    'CustomerKey': 'customer_key',\n",
    "    'StoreKey': 'store_key',\n",
    "    'ProductKey': 'product_key',\n",
    "    'Quantity': 'quantity',\n",
    "    'Currency Code': 'currency_code',\n",
    "    'Product Name': 'product_name',\n",
    "    'Brand': 'brand',\n",
    "    'Color': 'color',\n",
    "    'Unit Cost USD': 'unit_cost_usd',\n",
    "    'Unit Price USD': 'unit_price_usd',\n",
    "    'SubcategoryKey': 'subcategory_key',\n",
    "    'Subcategory': 'subcategory',\n",
    "    'CategoryKey': 'category_key',\n",
    "    'Category': 'category',\n",
    "    'Gender': 'gender',\n",
    "    'Name': 'name',\n",
    "    'City': 'city',\n",
    "    'State Code': 'state_code',\n",
    "    'State_x': 'state_x',\n",
    "    'Zip Code': 'zip_code',\n",
    "    'Country_x': 'country_x',\n",
    "    'Continent': 'continent',\n",
    "    'Birthday': 'birthday',\n",
    "    'Age': 'age',\n",
    "    'Country_y': 'country_y',\n",
    "    'State_y': 'state_y',\n",
    "    'Square Meters': 'square_meters',\n",
    "    'Open Date': 'open_date',\n",
    "    'Exchange': 'Exchanges'\n",
    "}, inplace=True)\n",
    "\n",
    "# Remove the 'date' column if it exists\n",
    "data.drop(columns=[col for col in data.columns if col.strip().lower() == 'date'], inplace=True, errors='ignore')\n",
    "\n",
    "# Convert date columns using a specific format if known, otherwise handle errors by coercion\n",
    "# Example format: '%Y-%m-%d' (change this if your format is different)\n",
    "data['order_date'] = pd.to_datetime(data['order_date'], format='%Y-%m-%d', errors='coerce')\n",
    "data['delivery_date'] = pd.to_datetime(data['delivery_date'], format='%Y-%m-%d', errors='coerce')\n",
    "data['birthday'] = pd.to_datetime(data['birthday'], format='%Y-%m-%d', errors='coerce')\n",
    "data['open_date'] = pd.to_datetime(data['open_date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Verify the modified DataFrame columns\n",
    "print(\"Columns after modification:\", data.columns.tolist())\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Manish@2001\",  # Replace with your MySQL password\n",
    "    database=\"eda1\"  # Ensure this database exists\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Prepare the insert statement dynamically based on DataFrame columns\n",
    "columns = list(data.columns)  # Get column names from DataFrame\n",
    "placeholders = ', '.join(['%s'] * len(columns))  # Create placeholders for SQL\n",
    "insert_query = f\"INSERT INTO merged_full_data ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "\n",
    "# Insert each row of data\n",
    "for index, row in data.iterrows():\n",
    "    # Convert NaT/NaN to None for MySQL\n",
    "    row = tuple(None if pd.isna(val) else val for val in row)\n",
    "    try:\n",
    "        cursor.execute(insert_query, row)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error at row {index}: {err}\")  # Print the error if there's one\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b91e3-2662-4a90-9d68-8450aa29586a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcae38a-09ee-40f4-ad68-68df66843b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8ba94-18c0-40e0-95a6-93987ef8ec36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
